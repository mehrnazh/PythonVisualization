{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrnazh/PythonVisualization/blob/main/Project_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Project template\n",
        "\n",
        "By Mehrnaz Hosseinzadeh M.D., National Brain Centre, Mental Health Research Centre, IUMS\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "z29bITDshRkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project team\n",
        "\n",
        "List your team members and (as appropriate) each team member's role on this project."
      ],
      "metadata": {
        "id": "9uA9JWxabKDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background and overview\n",
        "\n",
        "Introduce your question and motivation here.  Link to other resources or related work as appropriate. if you are using multiple coding notebooks, mention all of them here\n",
        ""
      ],
      "metadata": {
        "id": "F8_ThLy3bX5i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ8S_ZIBMMpI"
      },
      "source": [
        "# Setup\n",
        "\n",
        "This demonstration notebook provides a suggested set of libraries that you might find useful in crafting your data stories.  You should comment out or delete libraries that you don't use in your analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5X225WPGwDo",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae502ba-3c14-40ac-fae6-b39c2f6c4647"
      },
      "source": [
        "# @title import libraries\n",
        "!pip install hypertools\n",
        "\n",
        "# file system\n",
        "import os\n",
        "\n",
        "# number crunching\n",
        "import numpy as np # for handling large, multi-dimensional arrays and matrices.\n",
        "import pandas as pd #offers high-performance, easy-to-use data structures and data analysis tools.\n",
        "\n",
        "# data import\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas_datareader as pdr\n",
        "\n",
        "\n",
        "# data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly # pip: plotly==4.14.3\n",
        "import plotly.express as px\n",
        "import bokeh as bk\n",
        "import plotnine as pn\n",
        "import hypertools as hyp  #tool for dimentionality reduction. resource: https://github.com/ContextLab/hypertools\n",
        "import folium as fm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# For interactive visualizations\n",
        "import altair as alt\n",
        "import bokeh\n",
        "\n",
        "# For geospatial data\n",
        "import geopandas as gpd\n",
        "\n",
        "# For statistical analysis\n",
        "import statsmodels.api as sm # Provides statistical models and tests for time series analysis, regression, etc.\n",
        "import scipy as sp  # Built on NumPy, provides scientific computing algorithms and functions.\n",
        "\n",
        "# machine learning and stats\n",
        "import sklearn as sk # Scikit-learn: Offers a collection of machine learning algorithms.\n",
        "\n",
        "# For deep learning\n",
        "import torch # Open-source platforms for building and training deep neural networks."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hypertools\n",
            "  Downloading hypertools-0.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting PPCA>=0.0.2 (from hypertools)\n",
            "  Downloading ppca-0.0.4-py3-none-any.whl.metadata (400 bytes)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from hypertools) (1.3.2)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from hypertools) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from hypertools) (0.13.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from hypertools) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from hypertools) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from hypertools) (1.26.4)\n",
            "Collecting umap-learn>=0.4.6 (from hypertools)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from hypertools) (2.31.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->hypertools) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->hypertools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->hypertools) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->hypertools) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->hypertools) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->hypertools) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->hypertools) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5.1->hypertools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18.0->hypertools) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18.0->hypertools) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->hypertools) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->hypertools) (3.5.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.4.6->hypertools) (0.60.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.4.6->hypertools)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.4.6->hypertools) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->hypertools) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->hypertools) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->hypertools) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->hypertools) (2024.7.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.4.6->hypertools) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.5.1->hypertools) (1.16.0)\n",
            "Downloading hypertools-0.8.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ppca-0.0.4-py3-none-any.whl (6.7 kB)\n",
            "Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PPCA, pynndescent, umap-learn, hypertools\n",
            "Successfully installed PPCA-0.0.4 hypertools-0.8.0 pynndescent-0.5.13 umap-learn-0.5.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utex2jHYMh1G"
      },
      "source": [
        "# Google authentication\n",
        "\n",
        "Run the next cell to enable use of your Google credentials in uploading and downloading data via Google Drive.  See tutorial [here](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=P3KX0Sm0E2sF) for interacting with data via Google services."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnkRNlrJGwEA"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and upload your notebook\n",
        "\n",
        "Whether you're running this Jupyter notebook online or on your computer, it's essential to save your work from time to time. You can continue working on a saved notebook later or share it with friends and colleagues to let them execute your code. [GitHub](https://github.com/) offers an easy way of saving and sharing your Jupyter notebooks online."
      ],
      "metadata": {
        "id": "MgfMup23pEtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:**\n",
        "Create a GitHub Repository:\n",
        "\n",
        "Go to GitHub, sign in, and create a new repository. Copy the repository URL."
      ],
      "metadata": {
        "id": "KkoeFGo_pX_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Generate a Personal Access Token:\n",
        "\n",
        "* Go to GitHub Settings > Developer settings > Personal access tokens > Tokens (classic).\n",
        "* Click \"Generate new token,\" select scopes (e.g., repo), and generate the token.\n",
        "Copy the token.\n",
        "Open Google Colab:\n",
        "\n",
        "**Step 3:** Clone GitHub Repository in Colab\n"
      ],
      "metadata": {
        "id": "8kQq-Ll7penS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up git configuration\n",
        "!git config --global user.email \"your_email@example.com\"\n",
        "!git config --global user.name \"Your username\"\n",
        "\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "# Prompt for GitHub username and token\n",
        "username = input('GitHub Username: ')\n",
        "token = getpass('GitHub Token: ')\n",
        "\n",
        "# Construct GitHub URL with token for authentication\n",
        "repo_url = f'https://{username}:{token}@github.com/YOUR_GITHUB_USERNAME/YOUR_REPO_NAME.git'\n",
        "\n",
        "# Clone the repository\n",
        "!git clone {repo_url}"
      ],
      "metadata": {
        "id": "9b_P1Za-pl1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:** Navigate to the Repository Directory:"
      ],
      "metadata": {
        "id": "49z7_Nx1pr35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd YOUR_REPO_NAME"
      ],
      "metadata": {
        "id": "gGEm2ThVptop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5:** Copy the Notebook to the Repository Directory:\n",
        "\n",
        "* Copy the colab Notebook into your Google drive\n",
        "* Mount Google drive into Colab\n",
        "* Copy file from your Google Drive to your Repository Directory"
      ],
      "metadata": {
        "id": "OnEbK-lSpyS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # you need to give necessary access"
      ],
      "metadata": {
        "id": "ErTP-gT8p3Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the Notebook to the Repository Directory:\n",
        "# Replace 'your_notebook.ipynb' with the name of your notebook\n",
        "\n",
        "!cp /content/your_notebook.ipynb /content/YOUR_REPO_NAME/"
      ],
      "metadata": {
        "id": "MchbKhkHp6-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6:** Stage, Commit, and Push the Notebook to GitHub:"
      ],
      "metadata": {
        "id": "CaiBe-fkp-8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check repository status\n",
        "!git status"
      ],
      "metadata": {
        "id": "OhZ9aXoaqA5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stage the new notebook file\n",
        "!git add your_notebook.ipynb"
      ],
      "metadata": {
        "id": "Ydp6D0k9qIxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, you can run `commit` to\n",
        "capture and upload a snapshot of the notebook.\n",
        "you can add the following two cells at any part of the notebook to take the snapshot of your progress."
      ],
      "metadata": {
        "id": "QaCRncibqOCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Commit changes with a message\n",
        "!git commit -m \"Add Colab NoteBook\""
      ],
      "metadata": {
        "id": "xM3EvMMFqQY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Push changes to the main branch\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "l9mTN_AAqex2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXsl_Ks2NVf8"
      },
      "source": [
        "# Approach\n",
        "\n",
        "Briefly describe (at a high level) the approach you'll be taking to answer or explore your question in this notebook.\n",
        "\n",
        "# Quick summary\n",
        "\n",
        "Briefly describe your key findings at a high level.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHvFYl-aOHpN"
      },
      "source": [
        "# Data\n",
        "\n",
        "Briefly describe your dataset(s), including links to original sources.  Provide any relevant background information specific to your data sources."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## importing data, reading from and writing to files using Python\n",
        "\n",
        "You always need to be able to read your data from a source, inspect your data, be able to manipulate, and save the preprocessed data into a file. Follow this notebook for an extensive approach to work with files using Python: [Reading from and Writing to Files using Python](https://colab.research.google.com/drive/1_BkaSeHHkA58jVttXk11Dc2WHK5zxBq3#scrollTo=mbV8c98vwtXz).\n",
        "\n",
        "Below you can find some necessary code for start having your data to work with:"
      ],
      "metadata": {
        "id": "VxLI_bNccwED"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMalPJ-XMuVh"
      },
      "source": [
        "# Provide code for downloading or importing your data here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Work with local files\n",
        "\n",
        "Uploading files from your local file system:\n",
        "\n",
        "`files.upload` returns a dictionary of the files which were uploaded.\n",
        "The dictionary is keyed by the file name and values are the data which were uploaded.\n",
        "\n"
      ],
      "metadata": {
        "id": "uvvQDUsFf1Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# List the uploaded files\n",
        "for filename in uploaded.keys():\n",
        "    print(f'User uploaded file \"{filename}\" with length {len(uploaded[filename])} bytes')\n",
        "\n",
        "# Access the uploaded file\n",
        "import json\n",
        "\n",
        "# Assuming you uploaded 'FileName.json'\n",
        "data_json = json.loads(uploaded['FileName.json'])\n",
        "\n",
        "# Assuming you uploaded 'data.csv'\n",
        "data_csv = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "21jo-7XQfUSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading files to your local file system:\n",
        "\n",
        " `files.download` will invoke a browser download of the file to your local computer."
      ],
      "metadata": {
        "id": "4xqGGZu9geDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('example.txt', 'w') as f:\n",
        "  f.write('some content')\n",
        "\n",
        "files.download('example.txt')"
      ],
      "metadata": {
        "id": "7rSWcGyLgSdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive\n",
        "\n",
        "You can access files in Drive by Mounting your Google Drive in the runtime's virtual machine"
      ],
      "metadata": {
        "id": "a8s-Gdfrg3QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-e6NBGBehLu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/path_to_file/data.csv')"
      ],
      "metadata": {
        "id": "nNPnBfrXiMfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import data from a URL"
      ],
      "metadata": {
        "id": "4OPyn3Faf-AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# navigate the google drive\n",
        "import os\n",
        "os.makedirs('./data', exist_ok=True)"
      ],
      "metadata": {
        "id": "YroTRMoYpK3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_url = \"https://gist.githubusercontent.com/aakashns/afee0a407d44bbc02321993548021af9/raw/6d7473f0ac4c54aca65fc4b06ed831b8a4840190/movies.csv\"\n",
        "\n",
        "urlretrieve(movies_url, 'data/movies.csv')\n",
        "\n",
        "movies_dataframe = pd.read_csv('data/movies.csv')"
      ],
      "metadata": {
        "id": "8UH9vAZLgBdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hpbjrd8Ofpa"
      },
      "source": [
        "# Analysis\n",
        "\n",
        "Briefly describe each step of your analysis, followed by the code implementing that part of the analysis and/or producing the relevant figures.  (Copy this text block and the following code block as many times as are needed.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m3i6KItOypO"
      },
      "source": [
        "# Provide code for carrying out the part of your analysis described\n",
        "# in the previous text block.  Any statistics or figures should be displayed\n",
        "# in the notebook."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkYVN71FPIXE"
      },
      "source": [
        "# Interpretations and conclusions\n",
        "\n",
        "Describe and discuss your findings and say how they answer your question (or how they failed to answer your question).  Also describe the current state of your project-- e.g., is this a \"complete\" story, or is further exploration needed?\n",
        "\n",
        "# Future directions\n",
        "\n",
        "Describe some open questions or tasks that another interested individual or group might be able to pick up from, using your work as a starting point."
      ]
    }
  ]
}